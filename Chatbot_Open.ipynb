{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd400c92",
   "metadata": {},
   "source": [
    "1. Import all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c277a2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fatemehshahlaei/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from llama_index.core import Document  # Ensure correct version installed\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle\n",
    "import time\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import shutil\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a6485",
   "metadata": {},
   "source": [
    "2. Diversity-Based Chunking Algorithm Analysis (Optimal way to calculate chunk size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0303ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:16,  3.59it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq4AAAHWCAYAAAC2Zgs3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAATq5JREFUeJzt3QucTfX+//HPuN+J5FJIklsIFUqUXFJEnEqcKKrTSRJdpJI4FTonSkl1KtJFjoruIhURuSsqUYpyy3Xcr/v/eH/91/7tPbNnzB6zZ8+yX8/HYxmz9p61v/u7vmutz/quz/qupEAgEDAAAAAgh8sV7wIAAAAAGUHgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4IqT1plnnmlt27aNy2ePGzfOkpKSbOHChTH9nEsvvdRNAMI9+eSTVr16dTt69Kj53U033eT2Z36m/eGjjz5qiVTHnTt3tuuuuy5LlwkCV4QEWaHTaaedZpdddpl9+umnMfvcvXv3uh3ZV199FdXfbdq0ye699153UCpUqJAVLlzYGjRoYI899pjt2LHDTga//fab3XzzzValShUrUKCAlS1b1po2bWqDBg0yP/nxxx9de9J3OFnWTUpqw6HbjtpkxYoVrV27djZ27Fg7cOBAvIuYoz3xxBM2ZcqULF1mcnKyDR8+3Pr372+5cv3fYS7lfk77jpo1a7p9h/ZHyBgFeF4dqn5LlChhtWvXtttuu82+/fZbOxlk9vgUSu3v3XfftWXLlmVp2RJdnngXADnHkCFDrHLlyhYIBFxwqID2yiuvtA8//DAmPZfaMQwePNj9P6O9hgsWLHBl2r17t/397393AauoZ3PYsGE2a9YsmzZtmvnZ6tWr7YILLrCCBQtajx493EFiw4YNtnjxYncw9upMcvp3feONN1zQvX37dnvnnXfslltusZPVmDFjrEiRIi5Q/fPPP+2zzz5z6+/pp5+2jz76yCpUqBDvIubYwPVvf/ubdejQIcuW+eqrr9rhw4fthhtuSPVay5YtrVu3bu7/2o98/fXXNnDgQBdcTJo0KcvKcLI777zz7J577nH/37VrlztJVf3997//tb59+9qIESPC3r9v3z7Lkyfnhhwqd2jvfGaOTynVq1fPzj//fHvqqads/PjxWVbWRJdzWxGyXZs2bdxG5unZs6eVKVPGJkyYELdL7qHUY3fNNddY7ty5bcmSJa7HNdTjjz/udj5+N3LkSHdAXbp0qVWqVCnstc2bN4f9ni9fPsupdAL01ltvWZcuXWzNmjX25ptvZlngqgPMwYMHXU9uTqHg69RTTw3+/sgjj7jvrCDp2muvtXnz5sW1fIlEPd1XX311xPZxzjnnuJNez+233+7a0nvvvWf79+/PUW0qJzv99NPD6lF0Yq3tXfuwqlWr2j//+c/ga/Go1z179rhe9YzImzdvTMqgVAFdKXv++efdiS1OHKkCSJMu/6jXL+VZsoIG9SLVqlXL7YwU3P7jH/9wvWqh1AvaunVrdzDXctSbqx4o71J46dKl3f91VutddkovB+rFF190PVk6k08ZtIrK8fDDD6eaP3v2bLvwwgtdWc8666xUZ77epd60UihU1pR5s8dbZiSqH/3NGWecYStXrkzzfb/88ot7T8qgVZTCkV6Oa+glvJRT6CUv1aPWheosf/78bl2qlyqlZ5991r2my9+nnHKKO7FRMJoRc+bMcXWnPC9N6g3/448/Ur1P7emZZ55xlxpVn2oXV1xxRVh+sMp/5513ukBQ5VGZp06d6l7TSYxOuooVK+YODJdffnmqIPHQoUOunelgqs8oVaqUNWnSxKZPnx58z8aNG116hupeyy9Xrpy1b98+bP1Hq2vXri5Y1+XT0M8S9U7pioG2DW0jCgK0XlL66aef3MFP9aL3VqtWzR566KHj5uZFatdePeqzdYlcy2vcuLF9//33wW3s7LPPdnWkdhXpu+u7aP0UL17ctYtmzZq5dR3ps3X1QOXTvkTvV/2GXpLXexRcvPbaa8F2qvd7vXh33323+25aH2r76i3VlYf06CTpu+++sxYtWlhG6aqAPjt0X6eeWJ1wKO1Dn68ec/UkqucwVEbbjdKuLrnkEhdIFS1a1K666ipbsWJFqrIobeLcc89160A/J0+ebNFQgORtI+XLl7devXqlStPRutWyf/jhB5cSpvWoQFR5wSdC7en111+3kiVLuo4Enbx6Qvfvuvqi32fOnJlqGWqDem358uVh24BODLVc1Yv2Qx988EHE/bWWeccdd7j2onWS0bYUuh2ld3zSSZH+r/1OpKsH6lgJ3Y71OWrjKbd/ZB49rgjauXOnbdmyxe1s1LOnoMW7JB9KQap2EtpZ33XXXe5A8dxzz7kNWQcwnbnq71u1auU2/gceeMAduLQzUK+GaL4ureqMXL2oHTt2dPPr1KmTZvm0o9KOUTuwjNKBU+9X73H37t1dcKYdlAIG7dwzIzPLVL1qB7Zt2za3Y1XualoUsH7++ef2xRdfWPPmzaMqm04otM5CqfdDvbcK1kRpII0aNQoGMVoXOqjq+yg3UDt4Ue+11q++a58+fVxvlAICBS7qVTkeBZn6nkp70EFSB0f13t93331h79Pnqj0p+FSQp0u8ChoUfIZeAVB9/O9//3NlVqCng4wO/AoGFLTef//9ru3pwKcDs+q5YcOG7m91wBk6dKhbvk4e9D0VGOvApfUinTp1csvr3bu3W7basA42a9euPaGbNm688UZ76aWXXFqH91ne9qO6Ubm0ThS8a/vRdqTtRVTf+n76XsofVDl0YqP0HQUGmaG61bakgEb0+ToZU/0p6NFBXydZCmJ0cqN6D10HWk9q6+pFUn6jDuRqp1qu6jaUAm6dsOozVNcvv/yyCxrUMycKcrx1ou8n3rahnlAFOFrfCrK3bt3qThh1Sbp+/fppfr9vvvnG/UzrPWrH2h5FAYXqXIGz2nRo4KrgXkG29lHadubPn+/2iTr5Ck0pyEi70ffUvkIn8vruWq72fzp50vr23qc2ouXp+6rO9J29oDgj1M4VaCloV7l1gqzPUYqVt2/2aB3rBET7Xq0n1bVyMnUCqXWcWTp51D79lVdecYFxpH2igna9T9uzTnxCTZw40f2N9hmiur344otdYK1jiQJ//Z1SS5Q/qs8KpfarfZqueGj9ZqYtpXd8UnvWtqP9m1IBQmme9j0qq8c7QVT9pywrMimAhDd27FidFqea8ufPHxg3blzYe7/++mv32ptvvhk2f+rUqWHzJ0+e7H5fsGBBmp/7119/ufcMGjQoQ+U85ZRTAnXr1s3w96pUqZJb/qxZs4LzNm/e7L7XPffcE5ynz4+0KXj1smbNmqiX6f2tvv+GDRsCtWrVCpx11lmB33777bjlXr58eaBgwYLu788777xAnz59AlOmTAns2bMn1XubNWvmprT873//c8sZMmRIcF7Pnj0D5cqVC2zZsiXsvZ07dw4UL148sHfvXvd7+/btXbkz4+DBg4FSpUoFHnrooeC8Ll26pFp/X3zxhSvfXXfdlWoZR48eDf5f78mVK1dgxYoVYe/p0KFDIF++fIFffvklOG/9+vWBokWLBpo2bRqcp8+96qqr0izv9u3b3Wf8+9//jvq7eu1H7Tm9ZV9zzTXBujnttNMC5557bmDfvn3B93300UfufY888khwnr6Dvsvvv/+eZt10797dtcu0yhXK265D2/SLL77o5pctWzaQnJwcnD9gwICw9q/PrFq1aqB169Zhn6/2Urly5UDLli1TfXaPHj3CPl91oHYRqnDhwu47pKS22KtXr0C0Hn74YffZu3btSvVapP2cJrWj/fv3h73X2w5CDR06NJCUlBRcHxlpNypHiRIlArfeemvY/I0bN7rvGDpf27u2zR07dgTnTZs2zX1GpHUcSvshbQutWrUKHDlyJDj/ueeec3//6quvBudpn6F548ePD847cOCAawOdOnUKHI/Kkt72NHLkSLf8999/Pzgv5b7+hhtucNvB4cOHg/O0r9R2Hrq/uvzyywO1a9cOWz9qfxdddJFrjyn3uU2aNAlbZkbbUsrtKL3jk8pevnz5sHpevHixe7/KkdI555wTaNOmTbqfj4wjVQBBo0ePdj0FmnRTjS4hqTfE6yUV9TTokp96jtRr4U3qgdEZ9Jdffune5/UY6aYUXabNCuol0yW2aOhsVz1WoWfSutT666+/Zroc0SxTvTPqUVAd6FJ5pMv/Kam3QT2k6ulWL7V64tS7oMv60eTwqrdDPWa6bOmlUOj4oV4K3fGu/4euQ/UGqdfdu3ymdajyq7cmWurBVa9G6M0x+r9ugAm9PKqyqOc30mgJKS9zqx5V954jR464HirVjdI1PLpUq94z9aiozXjfRZ+7atWqiOVVj4jyhZVOkTLl5UR5eW26XCnq6VWvnHqGQvP+1AulFJiPP/7Y/f7XX3+5NqN1qMvVoSKltmSUUilCe5C9Xmn19IVuX958r12rTar+VLdat167Ua+Wlqmyphx6Sj1dobTd6G+99ZIerTP17q9fvz6q76flq+c0rXxCbQ/efu7999+3AQMGuLQTfa/QS9tqEx59R33Xiy66yL3Hu0yckXajz9GlerX/0O1Nl5RVx94+Uzdgqo7VM6t9rEf72tB2nxZdpVGurq6YhI6kcOutt7orEl678qh+Qq+m6Xuo5/tE9o2hyw5t85Fcf/31bjsITWFSr6jakF4TXaFSL796hLUsr+60jrW/UntMmV6j76u6zYq2lBblrWtZ3rrzelvVHrQdpaQ0K6+XHyeOwBVB2mnpEpMm5eZpR6cdpi6vaIco2lEouNHlPgVsoZMuUXs3DynI0Aasy1a6rKuDxYkODaSdb3o7wkhSHvC9nciJBCfRLFOXiVUnumwdevnoeHQDiS4vameny8XKndLBWJdTdYA6HgUGurylz1T+rRfoKBjSQVSXrlOuP12SFG8d6rKhDkBqF8oN1eWxlLmMadGJjy6pKZ9MqRWadAlY6QLawXt02Vt5eMpdOx4tL5S+iy656qQhpRo1argD4Lp164IjZuh7q151KVTpCqpXj8qpS7gKuHWCoKHHdKlc+Ysnykvd8ILC33//3f2MVG4Frt7rXgDhXTLNKinbrxckpRz1wJvvtWsv6FdglbLtKAVA27b2Del9lraT0GWmR/WvPEeVS21Ql8GzIqjSZXdvP6cbuLRtaTgsnaDrRNujS/1KAVLb1Hag7+ld1va+Z0bajVdvSqdIWW868fK2N2+9a1tLKVJbSSmtdqWAVCd23uuh9ZDyBOhE941ptflIvDxppQZ49H+NVqDtVLTf0ImCRn1IWXfeyW7KG1ZT7idi0ZZ0MqETZG9fpn2N0qB0nIv0nfUdTuRkE+HIcUWadNauXlf1+Gnnq55AbaAKWkODj1BeQrs2Up09K09R+Xje0EAaFkTzMnN3pQ7q6pFQEJ3Ru+lTnnl7Ut40EIl69DK7TI+CRwWOqkPlrEVLn6VAS5NuotH6UN0f78YTHXDVI6C8PAX8Hq9HTD0tCkAi8fKMFfwpR04Hc/VIqXdUOZDKHQsdkitS0Kx1rlzCSAdh3dyl/Mxod+ShPWDRUkChIFk9bAoWFGgp9/eFF14IjnSgnir1ROvmGLVXHSy1ztTjkzKXLRreTSa66SkWsqr9Hq9de23n3//+twsuIkm5XUezraSkXjb10OrmJK0zfa6CRAWY6eVgKh9VedI6yc3oFRr1GIt6jdUGVHdeTrpO4LTvUW6leve0bYX2LB+v3Xjv1YmobgJLKV5DRJ3IusmKNq+gX1dLtH61X1Get06MdSLh8epO43arhzWSlJ8RaT+R2baUXt2ph15XwFR2lVv725T3g3h0MhBpX4jMIXBFunQACD2DVq+ZevyULJ+RQEI3AWlSoKKART25b7/9tgsWog1cdHCYO3euC6Aijc+YWV4vkHrkvBQHSdlDkRm6YUM7VgV76l3QzQWZ5d2opEuK6dF4tjqIaqeccvQFnVjoYK4Dc0buutbBWpftNOmEQYG41qUur6Y1vI03rJBubggdHkoUCCttQTt63Zii9qSDvQKEjPS6pvwu6sGNNEKD7kLWiVdoL6KWr15lTWrPCmbV8xI6RJfKo7EpNelkTQGaTrbUg5xZCljEO/B66SIqd8qb7zTPe91Lfwi9uzqt9hvp4Q5Z0X5DeTdN6UQomjv2jye9/YB6tZRSoUk9a7qRRu0vvWDDa/O6aTS9mz3T289plIWff/7Z3bTljfkqad0Znl678epNJ/zp1Zu33iOls6Q3CknKv9d7Q1NntN2qLrJynaVHdagAUdueTn7To/2K6njGjBnuRikFzV6agHjfQzeVnWj5o21Lxzs+qV1oHeskXT3u2h9FCq7VtnTlR737yBqkCiBNysvU2al6N70dkM5cFfT861//iriBegdQnWGmPHP3emm8dAEFHZLRJyopX047Hx0cdFBJSTsjXfKLlndgUW+LxxuiJyuoB0Y9Bgr2FMwdj+7OjpQX/Mknnxz3sqFOKhQYarikSAO6q6dAKRwK/iMFRLr87lEeWSi1A6WOaL2ml7esg7UOOFpfGpEgdFI9qFfO67FXWbS8SD24x+v50XfRyBXqRQ0dekg9NzpJUmDs9Tan/C4qg04ovLaolAMF2ynbhYL8E0lvUTnUu6vecq9XTycgCmLU2xu6bB38dPBWrqvoQKjgWqNW6LJ1WnWjcurSdWjqg05uoh1G6XiUx67P+s9//pNq5IqUbScaOjlKuQ/QPiZl2oHqTGklx1sfqmuJ5nHLCj6kbt26Yb2RofWs/+vKSaiMtBsFM2qH6kmMtN149aZ9m/aR2u+EfncFy8pXPx4FdtpGR40aFVZu3d2v5XntKpY0VJjSo3Qiqn3Q8YI/lVknlEoR0KTL+KGX+rXOdZe+RgqJdMKekTaX2bZ0vOOTToo0afvW/lRD/kXqPde6UxtRfjSyBj2uCDtwqqfKCwJ10NXZv3oJvQBAOV4aDkuXwnTZXoGDzob1Pt24pR27AhTtfHUJRcN/aEeuy3a6rKLl6MlXoh5bBULaYSmnSTsw5fOlldOnniUdjPX32sGHPjlLNxQpx8g7aEVD30G5eBqWSbmPOmgpWFDgkDJgyCxdmtLOU3miOqildUlJdAlr0aJFrnfT6zHS91PKgerIG64qEvVEq9y6LJWyl1CXPpWHpx5Z3VSgG0N0I4PWgQ40+gwFvvq/Vy+6tKnedf2dgioNe6YDYFqXYL0bFjSMVlqXB3UgV1vRAVapDzrQ6f9qQ8p70+VBBe96TfnV6dGJig7sClLVk6IDhw5yOiCFjkmp76gDoNqL6lBBjTc8juhESIGlTsz0Xi1HbU1BsA5IGaHlKSBWD5f35Cz1LCsYCh0+SduL1rF6frU9aZ15w2HppimNFepRvei7qXdI+c06qCtIV/65tj9R+XQ5W9ua6t0baknb1PHGPI2GerB1kFYPldKGVH7lUOu7ap1r2/YCwGhonajdaXxmBRP6jjo5Uw6m9iWqP9Wr3qMbBdXLlR6dNGkfovd740aH0rr2tg3VlVKXtL/SiYzaotdrq/2WTrT0/fTdFJykzP/MSLvR32p9aNlaj5rv7Vu0HrV9absS7Ve1fWmdq+zaFr2xlCOdLITSMnVyrJNAbUfq4VPvq/bDGnYtvX1OZqhevHpU2RSgqZ0rv1edCzpOHI+2Be3ndBVOnQU6KYp007DqQ+lS2l9p/ap+dfVNN48e73GqOvZkpi1l5PikXle1EUmrfrV/UhDsDYWHLBDFCARIoOGwChQo4IZmGTNmTNjQN56XXnop0KBBAzdsk4br0XAl999/vxuKyBsaREOGVKxY0Q2/o2FP2rZtG1i4cGHYcr755hu3HA3jktGhsfQZffv2dUOMqJyFChVyy3j88ccDO3fuPO6QLZGGkFq0aFGgYcOGrhwq84gRI9IcDisjywwdDsujoVNUJ3ny5HHDW6Vlzpw5bugWDZekYVzy5s3rynTTTTeFDfsU6XPTGu5H05dffhl836ZNm9xnVKhQwS1fw+Bo2Bmt19BhkjQck4Yv0jqsUqVK4L777gur45Seeuop91kzZsxI8z0aYi10qBwNXaPhhKpXr+7qv3Tp0m7oGK2T0O+V1nA2amsaoqlIkSKuLVx22WWuXYV67LHHAhdeeKEblkhtVp+l9qKhqURDg2n5mq/hmVTvag8aTux4vKGfQredM844w7V3DUGUcpglz8SJEwP16tVzdVuyZMlA165dA3/88UfE4dE0jJTKrmVXq1YtMHDgwLD3aMgktRfVn15/44030hwOK2U9qn1HGtJJ7UXzJ02aFDZ/yZIlgY4dOwbbhbaJ6667LmydpzVEWKRt6qeffnLtzBsCTsMSaWgmtTUNY6b9i9aJ/v/8888HMkLbr9pDyiGtUm4TuXPnduvqtttuc9tEqB9++CHQokULt5xTTz3VDVu1bNmysCGPomk3qk+1U71H61Hbk7bplPvEd999N1CjRg1XtzVr1gy89957aQ55FomGv1J5tF2XKVMm8M9//tMN2xVK+4xIQ91l9HO8YQE1aXiwYsWKueWpjr799tuIf5PW/n369OnB5axbty7i32q/161bN7ef0vc6/fTT3fb1zjvvpLvPlYy2pUjf/XjHJw3fpTakY1Fa1B7+/ve/p/k6opekf7IiAAYAICfQ1Q31zKnXXVdSgFjQqC9K8dA9DEoJS0lXRdTLrisfad3QiOiR4woAOKnoRkg9CUwpOinHlgWyip6ApxxaL8UkJaVlKUWBoDVr0eMKAACQQRrqTDm96mVVLn7oQ3oQewSuAAAAGaQbPb/55ht3Y51uUIvm4TI4cQSuAAAA8AVyXAEAAOALBK4AAADwhZP+AQS6o1SDomvA9GgfMQoAAIDYU+aqHhihB5HogScJG7gqaA19XjkAAABypnXr1rmnnSVs4Oo9mlIV4T22NJb0LOpp06YFH4WK7EG9xwf1Hh/UOxIJ7T0xJCcnu47GtB4pnmMCVz3vWM/Z/vTTT91zo/W86LFjx9r5558f7DoeNGiQe879jh073PATeu6znsWeEV56gILW7Apc9VxifRYbWPah3uODeo8P6h2JhPaeWJKOk9YZ15uztm/f7gJRNUQFrhrQ96mnnrJTTjkl+B49sm/UqFH2wgsv2LfffmuFCxe21q1b2/79++NZdAAAAGSzuPa4Dh8+3HULq4fVU7ly5eD/1dv69NNP28MPP2zt27d388aPH29lypSxKVOmWOfOnVMt88CBA24K7Xr2ztg0xZr3GdnxWfg/1Ht8UO/xQb0jkdDeE8OhDK7fuD6AoGbNmq739I8//rCZM2e6p0/ccccdduutt7rXf/31V6tSpYotWbIk7Fm/zZo1c78/88wzqZb56KOP2uDBg1PNf+utt9ylBgAAAOQsShft0qWL7dy5M93UzrgGrgUKFHA/+/XrZ9dee60tWLDA+vTp49ICunfvHnykmkYGKFeuXPDvrrvuOpcDMXHixAz1uKpXd8uWLdmW4zp9+nRr2bIluTjZiHqPD+o9Pqh3JBLae2JITk62U0899biBa554j7Gqm7CeeOIJ93u9evVs+fLlwcA1M/Lnz++mlNTYs7PBZ/fn4RjqPT6o9/ig3pFIaO8nt4yu27jenKVeVKULhKpRo4atXbvW/b9s2bLu56ZNm8Leo9+91wAAAJAY4hq4Kg1g5cqVYfN+/vlnq1SpUvBGLQWoM2bMCOtK1ugCjRs3zvbyAgAAIH7imirQt29fu+iii1yqgPJW58+fby+99JKbRHmsd999tz322GNu3FYFsgMHDnSPA+vQoUM8iw4AAIBEClwvuOACmzx5sg0YMMCGDBniAlMNf9W1a9fge+6//37bs2eP3Xbbbe4BBE2aNLGpU6cGb+wCAABAYoj7k7Patm3rprSo11VBrSYAAAAkrrjmuAIAAAAZReAKAAAAXyBwBQAAgC8QuAIAAMAX4n5z1slq2bJllisX5wXZ+RQ2AABwciNwzWJ//PGH+9m0aVPbt29fvIuTMAoWLGgTJkxw9a9h1QAAwMmHwDWLbd261f0seUVvO1KsfLyLkzByJ68P1j+BKwAAJycC1xjJW/J0y3NqlXgXI2Ek5UmKdxEAAECMkYQJAAAAXyBwBQAAgC8QuAIAAMAXCFwBAADgCwSuAAAA8AUCVwAAAPgCgSsAAAB8gcAVAAAAvkDgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAAAAXyBwBQAAgC8QuAIAAMAXCFwBAADgCwSuAAAA8AUCVwAAAPgCgSsAAAB8gcAVAAAAvkDgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALcQ1cH330UUtKSgqbqlevHnx9//791qtXLytVqpQVKVLEOnXqZJs2bYpnkQEAAJCoPa61atWyDRs2BKfZs2cHX+vbt699+OGHNmnSJJs5c6atX7/eOnbsGNfyAgAAID7yxL0AefJY2bJlU83fuXOnvfLKK/bWW29Z8+bN3byxY8dajRo1bN68edaoUaM4lBYAAAAJG7iuWrXKypcvbwUKFLDGjRvb0KFDrWLFirZo0SI7dOiQtWjRIvhepRHotblz56YZuB44cMBNnuTkZPdTy9IUa0ePHnU/8+dJskDuQMw/D8ck5UkK1n92rGcc49U1dZ69qHckEtp7YjiUwfUb18C1YcOGNm7cOKtWrZpLExg8eLBdcskltnz5ctu4caPly5fPSpQoEfY3ZcqUca+lRYGvlpPStGnTrFChQpZdhrepaGZHsu3zoPq2YMoJstf06dPjXYSERL0jkdDeT2579+7N0PuSAoFAjukW3LFjh1WqVMlGjBhhBQsWtJtvvjms91QuvPBCu+yyy2z48OEZ7nGtUKGCbdmyxYoVKxbz77BkyRIXOPX/dK0FSlWO+efhmKSta9zJQrly5axevXrxLk5CnSHrYNKyZUvLmzdvvIuTMKh3JBLae2JITk62U0891aWKphevxT1VIJR6V8855xxbvXq1a6AHDx50wWxor6tGFYiUE+vJnz+/m1JSY8+OBp8r17H73Q4cDljgyLHL14i9pMOBYP2zY8t+2bV9IRz1jkRCez+5ZXTdxn1UgVC7d++2X375xfWaNWjQwH2JGTNmBF9fuXKlrV271uXCAgAAILHEtcf13nvvtXbt2rn0AA11NWjQIMudO7fdcMMNVrx4cevZs6f169fPSpYs6bqNe/fu7YJWRhQAAABIPHENXP/44w8XpG7dutVKly5tTZo0cUNd6f8ycuRId+lXDx5Q3mrr1q3t+eefj2eRAQAAkIiB69tvv53u6xoia/To0W4CAABAYstROa4AAABAWghcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAAAAXyBwBQAAgC8QuAIAAMAXCFwBAADgCwSuAAAA8AUCVwAAAPgCgSsAAAB8gcAVAAAAvkDgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAACAxAhck5OTbcqUKfbjjz9mTYkAAACArAhcr7vuOnvuuefc//ft22fnn3++m1enTh179913o10cAAAAEJvAddasWXbJJZe4/0+ePNkCgYDt2LHDRo0aZY899li0iwMAAABiE7ju3LnTSpYs6f4/depU69SpkxUqVMiuuuoqW7VqVbSLAwAAAGITuFaoUMHmzp1re/bscYFrq1at3Pzt27dbgQIFol0cAAAAkCF5LEp33323de3a1YoUKWKVKlWySy+9NJhCULt27WgXBwAAAMQmcL3jjjusYcOGtnbtWmvZsqXlynWs0/ass86yxx9/PNrFAQAAALFJFRgyZIjVqFHDrrnmGtfr6mnevLl9/vnn0S4OAAAAiE3gOnjwYNu9e3eq+Xv37nWvAQAAADkicNXwV0lJSanmL1u2LDjaAAAAABC3HNdTTjnFBayazjnnnLDg9ciRI64X9vbbb8/yAgIAAABRBa5PP/20623t0aOHSwkoXrx48LV8+fLZmWeeaY0bN6ZWAQAAEN/AtXv37u5n5cqV7aKLLrK8efPGpkQAAABAVuS4NmvWzHLnzm0///yzzZ49243fGjpl1rBhw1z6gcaJ9ezfv9969eplpUqVciMY6CldmzZtyvRnAAAAIIHGcZ03b5516dLFfv/9d5c6EEqBp/Jdo7VgwQJ78cUXrU6dOmHz+/btax9//LFNmjTJpSbceeed1rFjR5szZ07UnwEAAIAE63HVDVjnn3++LV++3LZt2+Ye9epN+j1auqlLT+L673//624A8+zcudNeeeUVGzFihBsjtkGDBjZ27Fj75ptvXPAMAACAxBJ1j+uqVavsnXfesbPPPjtLCqBUgKuuuspatGhhjz32WHD+okWL7NChQ26+p3r16laxYkWbO3euNWrUKOLyDhw44CZPcnKy+6llaYq1o0ePup/58yRZIHd4jzRiJylPUrD+s2M94xivrqnz7EW9I5HQ3hPDoQyu36gDVz3udfXq1VkSuL799tu2ePFilyqQ0saNG91oBSVKlAibX6ZMGfdaWoYOHRrxQQjTpk2zQoUKWXYZ3qaiBgrLts+D6ttsw4YNbkL2mj59eryLkJCodyQS2vvJTQ+yikng2rt3b7vnnntc8Fi7du1UowukzFNNy7p166xPnz6uIRYoUMCyyoABA6xfv35hPa4VKlSwVq1aWbFixSzWlixZ4gKn/p+utUCpyjH/PByTtHWNO1koV66c1atXL97FSagzZG3DLVu2ZKSRbES9I5HQ3hND8v+/Qp7lgavu7BeN5xp6U5b3RK2M3pylVIDNmzdb/fr1g/P0txqZ4LnnnrPPPvvMDh48aDt27AjrddWoAmXLlk1zufnz53dTSmrs2dHgc+U6ljZ84HDAAkdSP2EMsZF0OBCsf3Zs2S+7ti+Eo96RSGjvJ7eMrtuoA9c1a9ZkpjypXH755fb999+Hzbv55ptdHmv//v1dL6m+xIwZM4LB8sqVK23t2rU86AAAACABRR24VqpUKUs+uGjRonbuueeGzStcuLAbs9Wb37NnT3fZv2TJku4yv9IUFLSmdWMWAAAATl5RD4clr7/+ul188cVWvnx5N56r90jY999/P0sLN3LkSGvbtq3rcW3atKlLEXjvvfey9DMAAABwkgauY8aMcb2gV155pcs/9XJalYeq4PVEfPXVV2HL0E1bo0ePduPD7tmzxwWt6eW3AgAA4OQVdeD67LPPuocFPPTQQ+7Rrx49lCBlzioAAAAQt8BVN2dFGm5Id/KrVxQAAADIEYFr5cqVbenSpanmT5061WrUqJFV5QIAAABObFQB5bfqMa379+93Y7fOnz/fJkyY4J5Y9fLLL0e7OAAAACA2gestt9xiBQsWtIcfftg9nqtLly5udIFnnnnGOnfuHO3iAAAAgNgErtK1a1c3KXDdvXu3nXbaaZlZDAAAABDbwNVTqFAhNwEAAAA5LnDdunWrPfLII/bll1/a5s2b7ejRo2Gva8xVAAAAIO6B64033mirV692j2MtU6aMJSUlxaZkAAAAwIkErl9//bXNnj3b6tatG+2fAgAAANk3jmv16tVt3759mf9EAAAAIDsC1+eff9497nXmzJku3zU5OTlsAgAAAHJEqkCJEiVcgNq8efOw+XoYgfJdjxw5kpXlAwAAADIXuGr81rx589pbb73FzVkAAADIuYHr8uXLbcmSJVatWrXYlAgAAADIihzX888/39atWxftnwEAAADZ2+Pau3dv69Onj913331Wu3ZtlzYQqk6dOidWIgAAACArAtfrr7/e/ezRo0dwnvJcuTkLAAAAOSpwXbNmTWxKAgAAAGRl4FqpUqVo/wQAAADI/sB1/Pjx6b7erVu3EykPAAAAkDWBq27MCnXo0CHbu3ev5cuXzwoVKkTgCgAAgJwxHNb27dvDpt27d9vKlSutSZMmNmHChNiUEgAAAAkv6sA1kqpVq9qwYcNS9cYCAAAAOSpwlTx58tj69euzanEAAADAieW4fvDBB2G/a/zWDRs22HPPPWcXX3xxtIsDAAAAYhO4dujQIex3PXSgdOnS1rx5c3vqqaeiXRwAAAAQm8D16NGj0f4JAAAAkHNyXAEAAIAcFbh26tTJhg8fnmr+k08+addee21WlQsAAAA4scB11qxZduWVV6aa36ZNG/caAAAAkCMCVz1wQE/JSilv3ryWnJycVeUCAAAATixwrV27tk2cODHV/Lfffttq1qwZ7eIAAACA2IwqMHDgQOvYsaP98ssvbggsmTFjhnvc66RJk6JdHAAAABCbwLVdu3Y2ZcoUe+KJJ+ydd96xggULWp06dezzzz+3Zs2aRbs4AAAAIDaBq1x11VVuAgAAAHJ04CqLFi2yH3/80f2/Vq1aVq9evawsFwAAAHBigevmzZutc+fO9tVXX1mJEiXcvB07dthll13mbtDS418BAACAuI8q0Lt3b9u1a5etWLHCtm3b5qbly5e7obDuuuuuLC8gAAAAkKke16lTp7obsWrUqBGcp2GwRo8eba1ataJWAQAAkDN6XI8ePeoeNpCS5uk1AAAAIEcErhq7tU+fPrZ+/frgvD///NP69u1rl19+eVaXDwAAAMhc4Prcc8+5fNYzzzzTqlSp4qbKlSu7ec8++2y0iwMAAABik+NaoUIFW7x4sctz/emnn9w85bu2aNEi2kUBAAAAsR3HNSkpyVq2bOkmAAAAIMcFrrr5aty4cfbee+/Zb7/95gJYpQn87W9/sxtvvNH9DgAAAMQ1xzUQCNjVV19tt9xyi7sZq3bt2u6JWb///rvddNNNds0118SkgAAAAEBUPa7qaZ01a5bNmDHDPSUr1BdffGEdOnSw8ePHW7du3ahZAAAAxK/HdcKECfbggw+mClq9IbIeeOABe/PNN7O6fAAAAEB0get3331nV1xxRZqvt2nTxpYtW5bRxQEAAACxCVy3bdtmZcqUSfN1vbZ9+/boPh0AAADI6sD1yJEjlidP2imxuXPntsOHD2d0cQAAAEBsbs7SqAIaPSB//vwRXz9w4EB0n2xmY8aMcZOG1hKNUvDII4+4tAPZv3+/3XPPPfb222+75bdu3dqef/75dHt+AQAAkOCBa/fu3Y/7nmhHFDjjjDNs2LBhVrVqVRcYv/baa9a+fXtbsmSJC2L79u1rH3/8sU2aNMmKFy9ud955p3Xs2NHmzJkT1ecAAAAggQLXsWPHZvmHt2vXLuz3xx9/3PXAzps3zwW1r7zyir311ltu1AKvDHq8rF5v1KhRlpcHAAAAJ9kjX2NBObTqWd2zZ481btzYFi1aZIcOHbIWLVoE31O9enWrWLGizZ07N83AVSkFoWkLycnJ7qeWpSnW9HQxyZ8nyQK5AzH/PByTlCcpWP/ZsZ5xjFfX1Hn2ot6RSGjvieFQBtdv3APX77//3gWqymctUqSITZ482WrWrGlLly61fPnyWYkSJcLer/zWjRs3prm8oUOH2uDBg1PNnzZtmhUqVMiyy/A2FRWOZ9vnQfVttmHDBjche02fPj3eRUhI1DsSCe395LZ3715/BK7VqlVzQerOnTvtnXfecbm0M2fOzPTyBgwYYP369Qvrca1QoYK1atXKihUrZrGm/FwFTv0/XWuBUpVj/nk4JmnrGneyUK5cOatXr168i5NQZ8g6mLRs2dLy5s0b7+IkDOodiYT2nhiS//8V8hwfuKpX9eyzz3b/b9CggS1YsMCeeeYZu/766+3gwYO2Y8eOsF7XTZs2WdmyZdNcnkY9iDTygRp7djT4XLmOjTB24HDAAkeOXb5G7CUdDgTrnx1b9suu7QvhqHckEtr7yS2j6zZD47jWr18/+HCBIUOGZLg7NzOUo6gcVQWx+hIzZswIvrZy5Upbu3atSy0AAABAYslQj+uPP/7obpo65ZRTXP7o7bffniX5orqsrzFbdcPVrl273AgCX331lX322Wdu+KuePXu6y/4lS5Z0l/l79+7tglZGFAAAAEg8GQpczzvvPLv55putSZMmbrzV//znP+5Gqkj0AIGM2rx5sxv7VTmhClTr1KnjglblscjIkSPdpd9OnTqFPYAAAAAAiSdDgeu4ceNs0KBB9tFHH1lSUpJ9+umnER//qteiCVw1Tmt6ChQoYKNHj3YTAAAAEluejN75r8euinpAlXd62mmnxbpsAAAAQOZHFfAG2AcAAACyU6aGw/rll1/s6aefdjdtiR4Y0KdPH6tSpUpWlw8AAADI+HBYoXTzlALV+fPnu5upNH377bdWq1YtnmoBAACAnNPj+sADD1jfvn1t2LBhqeb3798/OCIAAAAAENceV6UHaHzVlHr06GE//PBDVpULAAAAOLHAtXTp0rZ06dJU8zWPkQYAAACQY1IFbr31Vrvtttvs119/tYsuusjNmzNnjg0fPtw95QoAAADIEYHrwIEDrWjRovbUU0+5R7ZK+fLl7dFHH7W77rorFmUEAAAAog9c9XQs3ZyladeuXW6eAlkAAAAgx43j6iFgBQAAQI69OQsAAACIBwJXAAAA+AKBKwAAAE6+wPXQoUN2+eWX26pVq2JXIgAAAOBEA9e8efPad999F82fAAAAAPFJFfj73/9ur7zyStZ8OgAAABCr4bAOHz5sr776qn3++efWoEEDK1y4cNjrI0aMiHaRAAAAQNYHrsuXL7f69eu7///888+pHk4AAAAA5IjA9csvv4xJQQAAAICYDIe1evVq++yzz2zfvn3u90AgkNlFAQAAAFkfuG7dutUNiXXOOefYlVdeaRs2bHDze/bsaffcc0+0iwMAAABiE7j27dvXDYu1du1aK1SoUHD+9ddfb1OnTo12cQAAAEBsclynTZvmUgTOOOOMsPlVq1a133//PdrFAQAAALHpcd2zZ09YT6tn27Ztlj9//mgXBwAAAMQmcL3kkkts/PjxYUNgHT161J588km77LLLol0cAAAAEJtUAQWoujlr4cKFdvDgQbv//vttxYoVrsd1zpw50S4OAAAAiE2P67nnnusePNCkSRNr3769Sx3o2LGjLVmyxKpUqRLt4gAAAIDY9LhK8eLF7aGHHsrMnwIAAADZF7hu377dXnnlFfvxxx/d7zVr1rSbb77ZSpYsmblSAAAAAFmdKjBr1iw788wzbdSoUS6A1aT/V65c2b0GAAAA5Ige1169ermHDYwZM8Zy587t5h05csTuuOMO99r3338fi3ICAAAgwUXd47p69Wr3aFcvaBX9v1+/fu41AAAAIEcErvXr1w/mtobSvLp162ZVuQAAAIDoUwW+++674P/vuusu69Onj+tdbdSokZs3b948Gz16tA0bNiwjiwMAAABiE7ied9557glZgUAgOE8PHkipS5cuLv8VAAAAiEvgumbNmiz/YAAAACDLA9dKlSpFtVAAAAAgRzyAYP369TZ79mzbvHmzHT16NOw15cACAAAAcQ9cx40bZ//4xz8sX758VqpUKZf76tH/CVwBAACQIwLXgQMH2iOPPGIDBgywXLmiHk0LAAAAyJSoI8+9e/da586dCVoBAACQraKOPnv27GmTJk2KTWkAAACArEoVGDp0qLVt29amTp1qtWvXtrx584a9PmLEiGgXCQAAAMQmcP3ss8+sWrVq7veUN2cBAAAAOSJwfeqpp+zVV1+1m266KSYFAgAAALIkxzV//vx28cUXR/tnAAAAQPYGrn369LFnn332xD4VAAAAiHWqwPz58+2LL76wjz76yGrVqpXq5qz33nsv2kUCAAAAWR+4lihRwjp27BjtnwEAAADZG7iOHTv2xD4RAAAAyAQefwUAAICTM3CtXLmynXXWWWlO0Y4Je8EFF1jRokXttNNOsw4dOtjKlSvD3rN//37r1auXlSpVyooUKWKdOnWyTZs2RVtsAAAAJFqqwN133x32+6FDh2zJkiXuSVr33XdfVMuaOXOmC0oVvB4+fNgefPBBa9Wqlf3www9WuHBh956+ffvaxx9/7B4zW7x4cbvzzjtdju2cOXOiLToAAAASKXDVcFiRjB492hYuXBjVshTshho3bpzreV20aJE1bdrUdu7caa+88oq99dZb1rx582CObY0aNWzevHnWqFGjaIsPAACARAlc09KmTRsbMGDACd28pUBVSpYs6X4qgFWPbosWLYLvqV69ulWsWNHmzp0bMXA9cOCAmzzJycnup5ajKdaOHj3qfubPk2SB3IGYfx6OScqTFKz/7FjPOMara+o8e1HvSCS098RwKIPrN8sC13feeScYcGaGAg6lIeipXOeee66bt3HjRsuXL58bgitUmTJl3Gtp5c0OHjw41fxp06ZZoUKFLLsMb1PRzI5k2+dB9W22YcMGNyF7TZ8+Pd5FSEjUOxIJ7f3ktnfv3tgErvXq1bOkpGO9WxIIBFwQ+ddff9nzzz9vmaVc1+XLl9vs2bPtRKjXt1+/fmE9rhUqVHC5s8WKFbNYU76vAqf+n661QKnKMf88HJO0dY07WShXrpxro8i+M2QdTFq2bJnqYSSIHeodiYT2nhiS//8V8iwPXHXnf6hcuXJZ6dKl7dJLL3WX8TNDN1zpSVyzZs2yM844Izi/bNmydvDgQduxY0dYr6tGFdBrkeTPn99NKamxZ0eDV33IgcMBCxz5vwAfsZV0OBCsf3Zs2S+7ti+Eo96RSGjvJ7eMrtuoA9dBgwZZVlFvbe/evW3y5Mn21VdfuaG2QjVo0MB9kRkzZrhhsETDZa1du9YaN26cZeUAAABAzpdlOa6ZTQ/QiAHvv/++G8vVy1vVsFcFCxZ0P3v27Oku/St/Vpf6FegqaGVEAQAAgMSS4cBVl2BDc1sj0esajzWjxowZ434qzSCURia46aab3P9HjhzpPls9rhotoHXr1ieUSwsAAICTPHDV5fy0aGiqUaNGBYeCiiZV4HgKFCjgxojVBAAAgMSV4cC1ffv2qeYp3/SBBx6wDz/80Lp27WpDhgzJ6vIBAAAAzrFb4KO0fv16u/XWW6127douNWDp0qX22muvWaVKlTKzOAAAACBrA1c92ap///529tln24oVK9zd/upt9R4YAAAAAMQ9VeDJJ5+04cOHu/FTJ0yYEDF1AAAAAIh74KpcVg1Rpd5WpQVoiuS9997LyvIBAAAA0QWu3bp1O+5wWAAAAEDcA9dx48bFrBAAAABATEYVAAAAALIbgSsAAAB8gcAVAAAAvkDgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAAAAXyBwBQAAgC8QuAIAAMAXCFwBAADgCwSuAAAA8AUCVwAAAPgCgSsAAAB8gcAVAAAAvkDgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAAAAXyBwBQAAgC8QuAIAAMAX4hq4zpo1y9q1a2fly5e3pKQkmzJlStjrgUDAHnnkEStXrpwVLFjQWrRoYatWrYpbeQEAAJCggeuePXusbt26Nnr06IivP/nkkzZq1Ch74YUX7Ntvv7XChQtb69atbf/+/dleVgAAAMRXnnh+eJs2bdwUiXpbn376aXv44Yetffv2bt748eOtTJkyrme2c+fO2VxaAAAAJGzgmp41a9bYxo0bXXqAp3jx4tawYUObO3dumoHrgQMH3ORJTk52Pw8dOuSmWDt69Kj7mT9PkgVyB2L+eTgmKU9SsP6zYz3jGK+uqfPsRb0jkdDeE8OhDK7fHBu4KmgV9bCG0u/ea5EMHTrUBg8enGr+tGnTrFChQpZdhrepaGZHsu3zoPo227Bhg5uQvaZPnx7vIiQk6h2JhPZ+ctu7d6+/A9fMGjBggPXr1y+sx7VChQrWqlUrK1asWMw/f8mSJS5w6v/pWguUqhzzz8MxSVvXuJMF3chXr169eBcnoc6QdTBp2bKl5c2bN97FSRjUOxIJ7T0xJP//K+S+DVzLli3rfm7atMkFIx79ft5556X5d/nz53dTSmrs2dHgc+U6dr/bgcMBCxw5dvkasZd0OBCsf3Zs2S+7ti+Eo96RSGjvJ7eMrtscO45r5cqVXfA6Y8aMsGhcows0btw4rmUDAABA9otrj+vu3btt9erVYTdkLV261EqWLGkVK1a0u+++2x577DGrWrWqC2QHDhzoxnzt0KFDPIsNAACARAtcFy5caJdddlnwdy83tXv37jZu3Di7//773Vivt912m+3YscOaNGliU6dOtQIFCsSx1AAAAEi4wPXSSy9147WmRU/TGjJkiJsAAACQ2HJsjisAAAAQisAVAAAAvkDgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAAAAXyBwBQAAgC8QuAIAAMAXCFwBAADgCwSuAAAA8AUCVwAAAPgCgSsAAAB8gcAVAAAAvkDgCgAAAF8gcAUAAIAvELgCAADAFwhcAQAA4AsErgAAAPAFAlcAAAD4AoErAAAAfIHAFQAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAAAAXyBwBQAAgC8QuAIAAMAXCFwBAADgCwSuAAAA8AUCVwAAAPhCnngXAID/LVu2zHLl4jw4uxw9etT9pN6z36mnnmoVK1aMdzGAhEXgCiDT/vjjD/ezadOmtm/fvngXJ2EULFjQJkyYQL3HQYGChWzlTz8SvAJxQuAKINO2bt3qfpa8orcdKVY+3sVJGIE/lrqf1Hv2OrR1nW396CnbsmULgSsQJwSuAE5Y3pKnW55Tq8S7GAnjcPJ695N6B5BofJEcNXr0aDvzzDOtQIEC1rBhQ5s/f368iwQAAIBsluMD14kTJ1q/fv1s0KBBtnjxYqtbt661bt3aNm/eHO+iAQAAIBvl+MB1xIgRduutt9rNN99sNWvWtBdeeMEKFSpkr776aryLBgAAgGyUo3NcDx48aIsWLbIBAwYE52nolxYtWtjcuXMj/s2BAwfc5Nm5c6f7uW3bNjt06FDMy5ycnGx79+61pG2/29GD+2P+eTgm1+5NtndvaVuyZInt3r073sVJGKtWrbIiRYrQ3rNZrl0b2c/EQdL29S5lTccl7euRfcO/qb1//fXXDP+WzcqUKWOnnXZatnzWrl273M9AIODfwFV3bh45csRVXCj9/tNPP0X8m6FDh9rgwYNTza9cuXLMyomcocvkeJcAyD5dPh8f7yIkrNtuuy3eRQBOWgpgixcv7s/ANTPUO6uc2NAzNfW2lipVypKSkmL++ToLr1Chgq1bt86KFSsW88/DMdR7fFDv8UG9I5HQ3hNDIBBwQWv58ukP8Zcnpz+hJHfu3LZp06aw+fq9bNmyEf8mf/78bgpVokQJy27auNjAsh/1Hh/Ue3xQ70gktPeTX3o9rZ4cnSySL18+a9Cggc2YMSOsB1W/N27cOK5lAwAAQPbK0T2uosv+3bt3t/PPP98uvPBCe/rpp23Pnj1ulAEAAAAkjhwfuF5//fX2119/2SOPPGIbN2608847z6ZOnZrqhq2cQmkKGnM2ZboCYot6jw/qPT6odyQS2jtCJQWON+4AAAAAkAPk6BxXAAAAwEPgCgAAAF8gcAUAAIAvELgCAADAFwhcM2DWrFnWrl079zQHPX1rypQpwdcOHTpk/fv3t9q1a1vhwoXde7p162br168PW8bPP/9s7du3dw9V0ADKTZo0sS+//DIO38Y/9PjeCy64wIoWLeqeldyhQwdbuXJl2HsuvfRSt05Cp9tvvz3VssaNG2d16tRxzxnXsnr16pWN38RfxowZ4+rKG+xbYyZ/+umnwdc1useNN97oHgKiNl+/fn179913Iy7rwIEDbiQQrZelS5dm47fwn0cffTRVW65evXrw9Zdeesm1d60TvbZjx46wv//tt9+sZ8+e7vHWBQsWtCpVqrg7sQ8ePBiHbwOk78wzz0zV3jWF7pvnzp1rzZs3d/sZtfumTZvavn37gq9zXE1MBK4ZoHFj69ata6NHj0712t69e23x4sU2cOBA9/O9995zwdXVV18d9r62bdva4cOH7YsvvrBFixa55WmeggBENnPmTLcTmzdvnk2fPt2dJLRq1cqtj1C33nqrbdiwITg9+eSTYa+PGDHCHnroIXvggQdsxYoV9vnnn1vr1q2z+dv4xxlnnGHDhg1z7XThwoXuwKGDg+pOdGKmNv7BBx/Y999/bx07drTrrrvOlixZkmpZ999//3Ef34f/U6tWrbC2PHv27LB9zRVXXGEPPvhgxL/96aef3ANaXnzxRbeuRo4caS+88EKa7wfiacGCBWFtXft4ufbaa4NBq9q79vnz589377/zzjstV67/C1s4riYoDYeFjFOVTZ48Od33zJ8/373v999/d7//9ddf7vdZs2YF35OcnOzmTZ8+PeZlPlls3rzZ1dnMmTOD85o1axbo06dPmn+zbdu2QMGCBQOff/55NpXy5HTKKacEXn75Zff/woULB8aPHx/2esmSJQP//e9/w+Z98skngerVqwdWrFjh1tuSJUuytcx+M2jQoEDdunWP+74vv/zS1ef27duP+94nn3wyULly5SwqIRA72o9XqVIlcPToUfd7w4YNAw8//HCa7+e4mrjocY2BnTt3ukseJUqUcL+XKlXKqlWrZuPHj3e9hTpDVK+ILlnrkbbIeL1KyZIlw+a/+eab7lLRueeeawMGDHA9Ux6dxasX6s8//7QaNWq43kT1Dq5bty7by+9HR44csbffftu1W+8xyxdddJFNnDjRtm3b5upWr+/fv99dxvZs2rTJ9YS//vrrVqhQoTh+A39ZtWqV66E+66yzrGvXrrZ27doT3mZSbi9ATqN0ljfeeMN69Ojhjp2bN2+2b7/91h0jtb/RA4eaNWsWdgWC42oCi3fkfLL1uO7bty9Qv379QJcuXcLmr1u3LtCgQYNAUlJSIHfu3IFy5coFFi9enA0lPjkcOXIkcNVVVwUuvvjisPkvvvhiYOrUqYHvvvsu8MYbbwROP/30wDXXXBN8fejQoYG8efMGqlWr5t43d+7cwOWXX+5+P3DgQBy+iT+oPtWzqrZavHjxwMcffxx8TT19rVq1cttCnjx5AsWKFQt89tlnwdfVY3LFFVcE/vWvf7nf16xZQ49rBqiH+n//+19g2bJlrq02btw4ULFiRdeLlJke11WrVrl189JLL8W45MCJmThxotvX/Pnnn+537afVxnUl59VXX3XHyrvvvjuQL1++wM8//xz8O46riYnANQsD14MHDwbatWsXqFevXmDnzp1hB/Krr7460KZNm8Ds2bMDixYtCvzzn/90Qdb69euzsfT+dfvttwcqVarkdlTpmTFjhltHq1evdr8//vjj7vfQwEopB7ly5XLBASJTUK/AZ+HChYEHHnggcOqpp7pL/nLnnXcGLrzwQpd+sXTp0sCjjz7qglsFu/LMM8+4E4zDhw+73wlcM0eBqQJPL0UjmsD1jz/+cJdde/bsmQ0lBU6MToTbtm0b/H3OnDmujQ8YMCDsfbVr13b7I+G4mrgIXLMocFXQ2qFDh0CdOnUCW7ZsCXtNB3gFSqHBrJx99tmuRxDp69WrV+CMM84I/Prrr8d97+7du9068oJSna3r95QB72mnnUZPVBTUS33bbbe5EwLV5/Lly1O9/o9//MP9v3379q69qwfEm/Q3+tmtW7c4fQN/Ov/884MH6owGruq1qlq1auDGG290VyqAnOy3335z+4spU6YE52lfrzb++uuvh733uuuuC17N5LiauMhxzQK62115k8pP0x3ryr0J5eVcht4N6f2uHEFEpvME3UU6efJkd9eohvk5Hm/IpXLlyrmfF198sfsZOoyWcjO3bNlilSpVilnZTzZqpxraKq22nDt37mBbHjVqlC1btsytC02ffPKJm6+82McffzwOpfen3bt32y+//BJsyxmhXG7lGivHb+zYsanWE5DTqJ0qL/Wqq64KGypLud4phz/U8FfefpvjagKLd+TsB7t27XKXOTWpykaMGOH+r1ED1NOqyxXqEdRl0w0bNgQnL4dSdz+WKlUq0LFjR/eelStXBu69916Xe6nfEZku++gS9FdffRVWr3v37nWvq/dvyJAh7nK2Lke///77gbPOOivQtGnTsOWoB7BWrVru8tP333/vLknVrFnTrTukph4+jdygOtXlf/2uHLJp06a5OlOPxiWXXBL49ttv3Tr4z3/+414PzYMNRapAxtxzzz2urau+1FZbtGjhUjSU2iJq+6pDjd7g3U2t37du3RpMD9C6Ue+3/h+6zQA5ka4IKI+7f//+qV4bOXKkS5WZNGmSS1vSCAMFChQIpoFxXE1cBK4Z4F2aSzl17949eFCONOnvPAsWLHB5PEo2L1q0aKBRo0buZgykLa16HTt2rHt97dq1LkhVnebPn98dtO+7775Ul470e48ePQIlSpRw79XNW/pbRKa6Uj6xboQoXbq0C4QUtHp0c4QOFkq3KFSokEuPSTk8VigC14y5/vrr3c0lqnfl6el37yDtDZeV3vagn2ltM0BOpHsP1D4VdEaiS/7qFNJ+Rjcrfv3112Gvc1xNTEn6J969vgAAAMDxkAAFAAAAXyBwBQAAgC8QuAIAAMAXCFwBAADgCwSuAAAA8AUCVwAAAPgCgSsAAAB8gcAVAAAAvkDgCgBZICkpyaZMmRLzz7n00kvt7rvvztJlPvroo3beeedl6TIBIBYIXAHgODZu3Gi9e/e2s846y/Lnz28VKlSwdu3a2YwZM8wPJk+ebI0aNbLixYtb0aJFrVatWmHB77333uub7wIgseWJdwEAICf77bff7OKLL7YSJUrYv//9b6tdu7YdOnTIPvvsM+vVq5f99NNPlpMpIL3++uvt8ccft6uvvtr1DP/www82ffr04HuKFCniJgDI6ehxBYB03HHHHS7Ymz9/vnXq1MnOOecc12PZr18/mzdvXth7t2zZYtdcc40VKlTIqlatah988EHwtXHjxrngN5RSC7TslJfsX3/9dTvzzDNdD2nnzp1t165daZbv448/du978803I77+4YcfusD7vvvus2rVqrnyd+jQwUaPHp3qcz0qU8pJ5fEsX77c2rRp44LdMmXK2I033ui+OwDEGoErAKRh27ZtNnXqVNezWrhw4VSvpwxEBw8ebNddd5199913duWVV1rXrl3dMqLxyy+/uID2o48+ctPMmTNt2LBhEd/71ltv2Q033OCCVn1WJGXLlrUVK1a4YDOjNmzYEJxWr15tZ599tjVt2tS9tmPHDmvevLnVq1fPFi5c6Opn06ZN7nsDQKwRuAJAGhS0BQIBq169eobef9NNN7lAUoHeE088Ybt373Y9tdE4evSo650999xz7ZJLLnG9mZHyT9Vjqt5g9ai2bds2zeUpN/eCCy5wKQ7qNVUP7quvvmoHDhxI828U7GpSb6p6atWj++KLL7rXnnvuORe06vupXvR/Le/LL7+0n3/+OarvCgDRIscVANKgoDUaderUCf5fPbTFihWzzZs3R7UMBZe6gcpTrly5VMt455133Lw5c+a4oDQ9KofSCdSTq+BS6Q333HOPPfPMMzZ37lyX1pCWBx980L1HPasFCxZ085YtW+aWEyknVp+hVAQAiBV6XAEgDcpTVX5nRm/Ayps3b9jv+lv1oEquXLlSBcK6ySuaZXjUy1m6dGnX05nR4LpKlSp2yy232Msvv2yLFy92N2hNnDgxzfe/8cYbNnLkSDciwemnnx6cr15kjaiwdOnSsGnVqlXBdAIAiBUCVwBIQ8mSJa1169busvyePXtSva58z4xSoKmbrEKXo4AvMxSEqtfz/fffd6kA0VKvrnpaI30nUS+rglylB2gYrVD169d3ObNahlIiQqdIecAAkJUIXAEgHQpajxw5YhdeeKG9++67rmfxxx9/tFGjRlnjxo0zvJyGDRu6YFGX33VJXTdWKZc1s3RJXsGrypTeAwk0YsD9999vX331la1Zs8aWLFliPXr0cL29LVu2jDhmrUZGUC6sgnb9rumvv/5yr+tGNd1wplzeBQsWuO+iocFuvvlmV08AEEsErgCQDj10QJfWL7vsMpcbqpumFPDphqkxY8ZE1Xury++ffPKJu1FqwoQJLqg8ERre6osvvnDLUtkiadasmf3666/WrVs3dzOVhrFSIDpt2jT39ykpLUKjBLz22msuv9abvFza8uXLu9xaBamtWrVy30WBs0ZYUDoEAMRSUiDauw8AAACAOOD0GAAAAL5A4AoAAABfIHAFAACALxC4AgAAwBcIXAEAAOALBK4AAADwBQJXAAAA+AKBKwAAAHyBwBUAAAC+QOAKAAAAXyBwBQAAgPnB/wO6QmnwEBhr1AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load SBERT\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Step 1: Text Cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s.,;:!?\\-()\\[\\]\\'\"]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Step 2: Chunking\n",
    "def chunk_text(text, chunk_size, overlap):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    return splitter.create_documents([text])\n",
    "\n",
    "# Step 3: Diversity Score (Average pairwise distance)\n",
    "def compute_diversity_score(chunks):\n",
    "    if len(chunks) < 2:\n",
    "        return 0\n",
    "\n",
    "    texts = [c.page_content for c in chunks]\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    sim_matrix = util.cos_sim(embeddings, embeddings)\n",
    "    \n",
    "    # Remove self-similarity and compute average of upper triangle\n",
    "    total_sim = 0\n",
    "    count = 0\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i+1, len(texts)):\n",
    "            total_sim += sim_matrix[i][j].item()\n",
    "            count += 1\n",
    "    avg_sim = total_sim / count if count else 0\n",
    "    return 1 - avg_sim  # higher = more diverse\n",
    "\n",
    "# Step 4: Run on all documents\n",
    "def find_best_chunk_sizes(data_dir, chunk_sizes=[128, 256, 384, 512, 768], overlap=50):\n",
    "    best_sizes = []\n",
    "\n",
    "    for file_path in tqdm(Path(data_dir).glob(\"*.txt\")):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        cleaned_text = preprocess_text(text)\n",
    "        best_score = -1\n",
    "        best_size = 0\n",
    "\n",
    "        for cs in chunk_sizes:\n",
    "            chunks = chunk_text(cleaned_text, cs, overlap)\n",
    "            if not chunks:\n",
    "                continue\n",
    "\n",
    "            score = compute_diversity_score(chunks)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_size = cs\n",
    "\n",
    "        best_sizes.append(best_size)\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(best_sizes, bins=range(min(chunk_sizes), max(chunk_sizes) + 150, 128), edgecolor='black')\n",
    "    plt.title(\"Best Chunk Sizes Across Documents (Based on Diversity)\")\n",
    "    plt.xlabel(\"Chunk Size\")\n",
    "    plt.ylabel(\"Number of Documents\")\n",
    "    plt.xticks(chunk_sizes)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return best_sizes\n",
    "\n",
    "data_dir = \"ancient_greece_data\"\n",
    "best_sizes = find_best_chunk_sizes(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a135acc3",
   "metadata": {},
   "source": [
    "3. Apply Chunking Technique with Optimal Chunk: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f310d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize text\"\"\"\n",
    "    text = re.sub(r'[^\\w\\s.,;:!?\\-()\\[\\]\\'\"]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def load_and_chunk_documents(data_dir, chunk_size, chunk_overlap):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_chunks = []\n",
    "    for file_path in tqdm(Path(data_dir).glob(\"*.txt\")):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        cleaned_text = preprocess_text(text)\n",
    "\n",
    "        chunks = text_splitter.create_documents(\n",
    "            texts=[cleaned_text],\n",
    "            metadatas=[{\n",
    "                \"file_name\": file_path.name,\n",
    "                \"file_path\": str(file_path),\n",
    "                \"chunk_id\": f\"{file_path.stem}_\"\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        # Add chunk ID\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk.metadata[\"chunk_id\"] += str(i)\n",
    "            all_chunks.append(chunk)\n",
    "\n",
    "    print(f\"\\n Total Chunks: {len(all_chunks)}\")\n",
    "    return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3b4885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:00, 2323.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total Chunks: 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "documents = load_and_chunk_documents(\"ancient_greece_data\", chunk_size=256, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac0aa5",
   "metadata": {},
   "source": [
    "4. Apply Embedding Technique using SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba39d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chunks for embedding...\n",
      "Doc 0 chunk_id: 1_0\n",
      "Doc 1 chunk_id: 1_1\n",
      "Doc 2 chunk_id: 1_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3d22cabf514544b4465b959c15dc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Checking metadata AFTER embedding:\n",
      "Doc 0 chunk_id: 1_0\n",
      "Doc 1 chunk_id: 1_1\n",
      "Doc 2 chunk_id: 1_2\n"
     ]
    }
   ],
   "source": [
    "# 1. choose model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "# 2. Extract content from chunks\n",
    "print(\"Preparing chunks for embedding...\")\n",
    "for i in range(3):\n",
    "    print(f\"Doc {i} chunk_id: {documents[i].metadata.get('chunk_id')}\")\n",
    "\n",
    "# Generate embeddings\n",
    "chunk_contents = [doc.page_content for doc in documents]\n",
    "chunk_embeddings = model.encode(\n",
    "    chunk_contents,\n",
    "    batch_size=4,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "# Apply embeddings on each chunk\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata['embedding'] = chunk_embeddings[i]\n",
    "\n",
    "#  check structure of embedding\n",
    "print(\"\\n Checking metadata AFTER embedding:\")\n",
    "for i in range(3):\n",
    "    print(f\"Doc {i} chunk_id: {documents[i].metadata.get('chunk_id')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb630c",
   "metadata": {},
   "source": [
    "5. Store the Embedding Vectors in a Vector Database (ChromaDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4bc2c",
   "metadata": {},
   "source": [
    "5. a. Clean the Database Before Storing Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25912d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client(Settings(\n",
    "    persist_directory=\"./my_new_chroma_db\",\n",
    "    anonymized_telemetry=False\n",
    "))\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"document_chunks\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5b53d",
   "metadata": {},
   "source": [
    " 5. b. Store Embedding Vectors in the Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2598e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 516 chunks in batches of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Success! Uploaded 516 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "total_chunks = len(documents)\n",
    "\n",
    "print(f\"Uploading {total_chunks} chunks in batches of {batch_size}\")\n",
    "\n",
    "for i in tqdm(range(0, total_chunks, batch_size), desc=\"Uploading\"):\n",
    "    batch = documents[i:i + batch_size]\n",
    "\n",
    "    ids = [doc.metadata[\"chunk_id\"] for doc in batch]\n",
    "    embeddings = [doc.metadata[\"embedding\"].tolist() for doc in batch]\n",
    "    \n",
    "    metadatas = [{\n",
    "        \"file_name\": doc.metadata[\"file_name\"],\n",
    "        \"file_path\": doc.metadata[\"file_path\"],\n",
    "        \"chunk_id\": doc.metadata.get(\"chunk_id\", \"UNKNOWN\"),\n",
    "        \"text\": doc.page_content[:50000]\n",
    "    } for doc in batch]\n",
    "\n",
    "    documents_list = [doc.page_content for doc in batch]\n",
    "\n",
    "    collection.upsert(\n",
    "        ids=ids,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas,\n",
    "        documents=documents_list\n",
    "    )\n",
    "\n",
    "print(f\"\\n Success! Uploaded {collection.count()} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0a8560",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      7\u001b[39m all_data = []\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdocuments\u001b[49m:\n\u001b[32m     10\u001b[39m     all_data.append({\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: doc.metadata[\u001b[33m\"\u001b[39m\u001b[33mchunk_id\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m: doc.metadata[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m].tolist(),   \u001b[38;5;66;03m# must be list\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m\"\u001b[39m: doc.page_content\n\u001b[32m     20\u001b[39m     })\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ðŸ’¾ Save to local .pkl file\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# 5c. SAVE EMBEDDING VECTORS TO LOCAL FILE\n",
    "# =====================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for doc in documents:\n",
    "    all_data.append({\n",
    "        \"id\": doc.metadata[\"chunk_id\"],\n",
    "        \"embedding\": doc.metadata[\"embedding\"].tolist(),   # must be list\n",
    "        \"metadata\": {\n",
    "            \"file_name\": doc.metadata[\"file_name\"],\n",
    "            \"file_path\": doc.metadata[\"file_path\"],\n",
    "            \"chunk_id\": doc.metadata.get(\"chunk_id\", \"UNKNOWN\"),\n",
    "            \"text\": doc.page_content[:50000]              # keep text short\n",
    "        },\n",
    "        \"document\": doc.page_content\n",
    "    })\n",
    "\n",
    "# ðŸ’¾ Save to local .pkl file\n",
    "with open(\"embedded_chunks_safe.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_data, f)\n",
    "\n",
    "print(\"âœ… Embeddings saved to 'embedded_chunks_safe.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62141f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 5d. LOAD EMBEDDINGS BACK FOR TESTING\n",
    "# =====================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"embedded_chunks_safe.pkl\", \"rb\") as f:\n",
    "    local_embedded_docs = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… Loaded {len(local_embedded_docs)} embedded chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea33ab3",
   "metadata": {},
   "source": [
    "6.  Pipeline to Retrieve Top-K Relevant Documents using Hybrid Search and Re-ranking Technique By Calling Embedding Vectors From Chroma DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62aba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Load embedding and cross-encoder models\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# Get documents and metadata from Chroma collection\n",
    "res = collection.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "# Flatten it\n",
    "docs_flat = sum(res[\"documents\"], []) if isinstance(res[\"documents\"][0], list) else res[\"documents\"]\n",
    "metas_flat = sum(res[\"metadatas\"], []) if isinstance(res[\"metadatas\"][0], list) else res[\"metadatas\"]\n",
    "\n",
    "# Build corpus\n",
    "corpus = [\n",
    "    {\"text\": doc, \"metadata\": meta}\n",
    "    for doc, meta in zip(docs_flat, metas_flat)\n",
    "]\n",
    "\n",
    "# Pre-tokenize corpus for BM25\n",
    "tokenized_corpus = [doc[\"text\"].split() for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Hybrid search function\n",
    "def hybrid_search(query, top_k=5, similarity_threshold=0.5):\n",
    "    # Step 1: Vector search\n",
    "    query_embedding = embedding_model.encode(query, normalize_embeddings=True)\n",
    "    vector_results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=top_k * 3,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    vector_hits = [\n",
    "        {\"text\": doc, \"metadata\": meta}\n",
    "        for doc, meta in zip(vector_results[\"documents\"][0], vector_results[\"metadatas\"][0])\n",
    "    ]\n",
    "\n",
    "    # Step 2: keyword search: BM25\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "    top_bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k * 3]\n",
    "    bm25_hits = [{\"text\": corpus[i][\"text\"], \"metadata\": corpus[i][\"metadata\"]} for i in top_bm25_indices]\n",
    "    # Step 4: Merge results\n",
    "    combined_docs = {doc[\"text\"]: doc for doc in vector_hits + bm25_hits}\n",
    "    combined_list = list(combined_docs.values())\n",
    "    # Step 5: Semantic similarity filter (instead of exact string match)\n",
    "    query_emb = embedding_model .encode([query])\n",
    "    doc_embs = embedding_model.encode([doc[\"text\"] for doc in combined_list])\n",
    "    sims = cosine_similarity(query_emb, doc_embs)[0]\n",
    "    # Keep only documents with similarity above threshold value\n",
    "    filtered_docs = [\n",
    "        doc for doc, sim in zip(combined_list, sims)\n",
    "        if sim > similarity_threshold\n",
    "    ]\n",
    "\n",
    "    if not filtered_docs:\n",
    "        print(\" No relevant document found for the query.\")\n",
    "        return []\n",
    "\n",
    "    # Step 6: Re-rank\n",
    "    cross_inp = [(query, doc[\"text\"]) for doc in filtered_docs]\n",
    "    scores = cross_encoder.predict(cross_inp)\n",
    "    reranked = sorted(zip(scores, filtered_docs), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    return [doc for _, doc in reranked[:top_k]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a76bde",
   "metadata": {},
   "source": [
    "7. Ollama Model with Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b119fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic==1.10.13\n",
      "  Using cached pydantic-1.10.13-cp311-cp311-win_amd64.whl.metadata (150 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\niraj\\appdata\\roaming\\python\\python311\\site-packages (from pydantic==1.10.13) (4.12.2)\n",
      "Using cached pydantic-1.10.13-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.11.7\n",
      "    Uninstalling pydantic-2.11.7:\n",
      "      Successfully uninstalled pydantic-2.11.7\n",
      "Successfully installed pydantic-1.10.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-chroma 0.2.1 requires langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-experimental 0.3.3 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.0.20 which is incompatible.\n",
      "langchain-experimental 0.3.3 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-google-genai 2.0.9 requires langchain-core<0.4.0,>=0.3.27, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-google-genai 2.0.9 requires pydantic<3,>=2, but you have pydantic 1.10.13 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-openai 0.2.12 requires langchain-core<0.4.0,>=0.3.21, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-openai 0.2.12 requires openai<2.0.0,>=1.55.3, but you have openai 1.3.5 which is incompatible.\n",
      "langchain-pinecone 0.2.2 requires langchain-core<0.4.0,>=0.3.29, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-tests 0.3.8 requires langchain-core<0.4.0,>=0.3.22, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-text-splitters 0.3.3 requires langchain-core<0.4.0,>=0.3.25, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langgraph 0.4.8 requires pydantic>=2.7.4, but you have pydantic 1.10.13 which is incompatible.\n",
      "langgraph-checkpoint 2.1.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langgraph-prebuilt 0.2.2 requires langchain-core>=0.3.22, but you have langchain-core 0.1.23 which is incompatible.\n",
      "litellm 1.74.2 requires openai>=1.68.2, but you have openai 1.3.5 which is incompatible.\n",
      "litellm 1.74.2 requires pydantic<3.0.0,>=2.5.0, but you have pydantic 1.10.13 which is incompatible.\n",
      "llama-cloud-services 0.6.54 requires llama-index-core>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-cloud-services 0.6.54 requires pydantic!=2.10,>=2.8, but you have pydantic 1.10.13 which is incompatible.\n",
      "llama-index-instrumentation 0.4.0 requires pydantic>=2.11.5, but you have pydantic 1.10.13 which is incompatible.\n",
      "llama-index-llms-openai 0.1.31 requires openai<2.0.0,>=1.40.0, but you have openai 1.3.5 which is incompatible.\n",
      "llama-index-workflows 1.2.0 requires pydantic>=2.11.5, but you have pydantic 1.10.13 which is incompatible.\n",
      "ollama 0.4.7 requires pydantic<3.0.0,>=2.9.0, but you have pydantic 1.10.13 which is incompatible.\n",
      "opik 1.8.2 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.13 which is incompatible.\n",
      "pydantic-settings 2.7.0 requires pydantic>=2.7.0, but you have pydantic 1.10.13 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.13 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.7.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\niraj\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\niraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.1)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.13\n",
      "    Uninstalling pydantic-1.10.13:\n",
      "      Successfully uninstalled pydantic-1.10.13\n",
      "Successfully installed pydantic-2.11.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-chroma 0.2.1 requires langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-experimental 0.3.3 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.0.20 which is incompatible.\n",
      "langchain-experimental 0.3.3 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-google-genai 2.0.9 requires langchain-core<0.4.0,>=0.3.27, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-openai 0.2.12 requires langchain-core<0.4.0,>=0.3.21, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-openai 0.2.12 requires openai<2.0.0,>=1.55.3, but you have openai 1.3.5 which is incompatible.\n",
      "langchain-pinecone 0.2.2 requires langchain-core<0.4.0,>=0.3.29, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-tests 0.3.8 requires langchain-core<0.4.0,>=0.3.22, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain-text-splitters 0.3.3 requires langchain-core<0.4.0,>=0.3.25, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langgraph-checkpoint 2.1.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langgraph-prebuilt 0.2.2 requires langchain-core>=0.3.22, but you have langchain-core 0.1.23 which is incompatible.\n",
      "litellm 1.74.2 requires openai>=1.68.2, but you have openai 1.3.5 which is incompatible.\n",
      "llama-cloud-services 0.6.54 requires llama-index-core>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-llms-openai 0.1.31 requires openai<2.0.0,>=1.40.0, but you have openai 1.3.5 which is incompatible.\n",
      "ragas 0.0.14 requires pydantic<2.0, but you have pydantic 2.11.7 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ollama\n",
      "Version: 0.4.7\n",
      "Summary: The official Python client for Ollama.\n",
      "Home-page: https://ollama.com\n",
      "Author: Ollama\n",
      "Author-email: hello@ollama.com\n",
      "License: MIT\n",
      "Location: C:\\Users\\niraj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: httpx, pydantic\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip install pydantic==1.10.13\n",
    "! pip install ollama\n",
    "!pip show ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2682c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def format_prompt(query, retrieved_docs):\n",
    "    \"\"\"Create a prompt template\"\"\"\n",
    "    context_blocks = []\n",
    "    sources_used = set()  # Track which sources are provided\n",
    "    \n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        # Extract clean source identifier\n",
    "        file_name = doc['metadata'].get('file_name', 'unknown_source')\n",
    "        source_id = file_name.replace('.txt', '')  #\n",
    "        \n",
    "        # Format context block with source id\n",
    "        context_block = f\"[[SOURCE: {source_id}]]\\n{doc['text'][:1000]}\\n\"\n",
    "        context_blocks.append(context_block)\n",
    "        sources_used.add(source_id)\n",
    "    \n",
    "    context = \"\\n\".join(context_blocks)\n",
    "    \n",
    "    prompt = f\"\"\"## Instruction\n",
    "You are a helpful assistant. Answer the question using ONLY the following context.\n",
    "You MUST cite sources using [[SOURCE: name]] format for EVERY factual claim.\n",
    "If the answer is not present, respond: \"I don't have enough information to answer this question.\"\n",
    "\n",
    "## Available Sources\n",
    "{', '.join(sources_used)}\n",
    "\n",
    "## Context\n",
    "{context}\n",
    "\n",
    "## Question\n",
    "{query}\n",
    "\n",
    "## Answer (with citations):\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def generate_answer(query, retrieved_docs, model_name=\"llama3.2:1b\"):\n",
    "    \"\"\"Generate answer with proper source attribution\"\"\"\n",
    "    prompt = format_prompt(query, retrieved_docs)\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You must cite sources for all factual information using [[SOURCE: name]] format.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        options={\n",
    "            \"temperature\": 0.1,  # More deterministic output\n",
    "            \"num_ctx\": 512  # smallercontext window\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response['message']['content'].strip()\n",
    "\n",
    "def extract_citations(answer):\n",
    "    \"\"\"Helper to parse and format citations\"\"\"\n",
    "    import re\n",
    "    sources = set(re.findall(r'\\[\\[SOURCE: (.*?)\\]\\]', answer))\n",
    "    if sources:\n",
    "        return f\"\\n Sources: {', '.join(f'[{src}]' for src in sources)}\"\n",
    "    return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6859a",
   "metadata": {},
   "source": [
    "8. LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "168179f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What purpose did the tales of ancient Greek heroes serve beyond entertainment?\n",
      "\n",
      " LLM response:\n",
      "I don't have enough information to answer this question.\n",
      "\n",
      "The provided context does not mention the purpose served by the tales of ancient Greek heroes beyond entertainment. In fact, it only mentions that they \"entertained with their tales\" and were important cultural symbols, but it does not elaborate on other possible purposes they may have served.\n",
      "\n",
      "\n",
      " Retrieved Documents:\n",
      "\n",
      "â€¢ [8]:\n",
      "  . These legendary heroes of ancient Greece not only entertained with their tales but also served as important cultural symbols. They embodied qualities that were highly valued in Greek society, such a...\n",
      "\n",
      "â€¢ [9]:\n",
      "  The tales of these heroes also served as a means of explaining natural phenomena and human experiences. For example, Heracles's Twelve Labors could be seen as symbolic representations of the challenge...\n",
      "\n",
      "â€¢ [7]:\n",
      "  The Legendary Heroes of Ancient Greece Ancient Greece is known for its rich mythology and fascinating stories of heroes. These legendary figures have left a lasting impact on Greek culture and continu...\n"
     ]
    }
   ],
   "source": [
    "query = \"What purpose did the tales of ancient Greek heroes serve beyond entertainment?\"\n",
    "retrieved_docs = hybrid_search(query)  \n",
    "answer = generate_answer(query, retrieved_docs)\n",
    "print(\"Query:\", query)\n",
    "print(\"\\n LLM response:\")\n",
    "print(answer)\n",
    "print(extract_citations(answer))\n",
    "print(\"\\n Retrieved Documents:\")\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs[:3]):  # Show top 3 sources\n",
    "    source = doc['metadata'].get('file_name', 'unknown')\n",
    "    print(f\"\\nâ€¢ [{source.replace('.txt', '')}]:\")\n",
    "    print(f\"  {doc['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92400ed",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31295365",
   "metadata": {},
   "source": [
    "1. Calculate Model Metrices to Evaluate LLM Response: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a17a9c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentence: I don't have enough information to answer this question.\n",
      "  ROUGE-1: 0.023\n",
      "  ROUGE-2: 0.000\n",
      "  ROUGE-L: 0.023\n",
      "  BLEU   : 0.000\n",
      "\n",
      " Sentence: The provided context does not mention the purpose served by the tales of ancient Greek heroes beyond entertainment.\n",
      "  ROUGE-1: 0.133\n",
      "  ROUGE-2: 0.034\n",
      "  ROUGE-L: 0.099\n",
      "  BLEU   : 0.000\n",
      "\n",
      " Sentence: In fact, it only mentions that they \"entertained with their tales\" and were important cultural symbols, but it does not elaborate on other possible purposes they may have served.\n",
      "  ROUGE-1: 0.188\n",
      "  ROUGE-2: 0.053\n",
      "  ROUGE-L: 0.104\n",
      "  BLEU   : 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\niraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def evaluate_rouge_bleu(answer, contexts):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    smoothing = SmoothingFunction().method4\n",
    "\n",
    "    all_context = \" \".join(contexts).lower()\n",
    "    sentences = sent_tokenize(answer)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, sent in enumerate(sentences):\n",
    "        sent_clean = sent.strip()\n",
    "        rouge = scorer.score(sent_clean, all_context)\n",
    "        bleu = sentence_bleu(\n",
    "            [word_tokenize(all_context)],\n",
    "            word_tokenize(sent_clean),\n",
    "            smoothing_function=smoothing\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"sentence\": sent_clean,\n",
    "            \"rouge1\": rouge[\"rouge1\"].fmeasure,\n",
    "            \"rouge2\": rouge[\"rouge2\"].fmeasure,\n",
    "            \"rougeL\": rouge[\"rougeL\"].fmeasure,\n",
    "            \"bleu\": bleu\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "scores = evaluate_rouge_bleu(answer, [doc[\"text\"] for doc in retrieved_docs])\n",
    "\n",
    "for s in scores:\n",
    "    print(f\"\\n Sentence: {s['sentence']}\")\n",
    "    print(f\"  ROUGE-1: {s['rouge1']:.3f}\")\n",
    "    print(f\"  ROUGE-2: {s['rouge2']:.3f}\")\n",
    "    print(f\"  ROUGE-L: {s['rougeL']:.3f}\")\n",
    "    print(f\"  BLEU   : {s['bleu']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2dda0b",
   "metadata": {},
   "source": [
    "# Evaluate of Retrival System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca8a0e2",
   "metadata": {},
   "source": [
    "1. Similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10670236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Score: 0.7156\n",
      "    Source: 8.txt\n",
      "    Excerpt: . These legendary heroes of ancient Greece not only entertained with their tales but also served as important cultural symbols. They embodied qualitie...\n",
      "\n",
      "[2] Score: 0.6318\n",
      "    Source: 8.txt\n",
      "    Excerpt: . The stories of these heroes were often used as cautionary tales or as examples of virtue to inspire and guide individuals...\n",
      "\n",
      "[3] Score: 0.5978\n",
      "    Source: 7.txt\n",
      "    Excerpt: The Legendary Heroes of Ancient Greece Ancient Greece is known for its rich mythology and fascinating stories of heroes. These legendary figures have ...\n",
      "\n",
      "[4] Score: 0.5771\n",
      "    Source: 9.txt\n",
      "    Excerpt: . In conclusion, the legendary heroes of ancient Greece, such as Heracles, Theseus, and Perseus, have left an indelible mark on Greek culture and cont...\n",
      "\n",
      "[5] Score: 0.5461\n",
      "    Source: 9.txt\n",
      "    Excerpt: The tales of these heroes also served as a means of explaining natural phenomena and human experiences. For example, Heracles's Twelve Labors could be...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. Load sentence embedding model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "def score_similarity(query, docs):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    doc_embeddings = model.encode(docs, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(query_embedding, doc_embeddings)\n",
    "    return scores.squeeze().tolist()\n",
    "\n",
    "# 5. Get scores\n",
    "doc_texts = [doc['text'] for doc in retrieved_docs]\n",
    "scores = score_similarity(query, doc_texts)\n",
    "\n",
    "# 6. Pair each document with its score and sort by score descending\n",
    "ranked = sorted(zip(retrieved_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 7. Display ranked results\n",
    "for i, (doc, score) in enumerate(ranked, 1):\n",
    "    print(f\"[{i}] Score: {score:.4f}\")\n",
    "    print(f\"    Source: {doc['metadata'].get('file_name', 'N/A')}\")\n",
    "    print(f\"    Excerpt: {doc['text'][:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f9f3cc",
   "metadata": {},
   "source": [
    "2. Keyword Coverage Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7015d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " KEYWORD COVERAGE EVALUATION:\n",
      "[1] Coverage Score: 0.4444\n",
      "    Source: 8.txt\n",
      "    Excerpt: . These legendary heroes of ancient Greece not only entertained with their tales but also served as important cultural symbols. They embodied qualitie...\n",
      "\n",
      "[2] Coverage Score: 0.3333\n",
      "    Source: 7.txt\n",
      "    Excerpt: The Legendary Heroes of Ancient Greece Ancient Greece is known for its rich mythology and fascinating stories of heroes. These legendary figures have ...\n",
      "\n",
      "[3] Coverage Score: 0.3333\n",
      "    Source: 9.txt\n",
      "    Excerpt: . In conclusion, the legendary heroes of ancient Greece, such as Heracles, Theseus, and Perseus, have left an indelible mark on Greek culture and cont...\n",
      "\n",
      "[4] Coverage Score: 0.2222\n",
      "    Source: 9.txt\n",
      "    Excerpt: The tales of these heroes also served as a means of explaining natural phenomena and human experiences. For example, Heracles's Twelve Labors could be...\n",
      "\n",
      "[5] Coverage Score: 0.2222\n",
      "    Source: 8.txt\n",
      "    Excerpt: . The stories of these heroes were often used as cautionary tales or as examples of virtue to inspire and guide individuals...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def score_keyword_coverage(query, docs):\n",
    "    \"\"\"\n",
    "    Measures how well retrieved documents cover important query terms\n",
    "    Returns scores from 0-1 for each document\n",
    "    \"\"\"\n",
    "    # Remove stop words from query\n",
    "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'what', 'how', 'why', 'when', 'where'}\n",
    "    query_words = set(re.findall(r'\\b\\w+\\b', query.lower())) - stop_words\n",
    "    \n",
    "    if not query_words:\n",
    "        return [0.0] * len(docs)\n",
    "    \n",
    "    scores = []\n",
    "    for doc in docs:\n",
    "        doc_words = set(re.findall(r'\\b\\w+\\b', doc.lower()))\n",
    "        matched_words = query_words.intersection(doc_words)\n",
    "        coverage_score = len(matched_words) / len(query_words)\n",
    "        scores.append(coverage_score)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "# Get keyword coverage scores\n",
    "doc_texts = [doc['text'] for doc in retrieved_docs]\n",
    "coverage_scores = score_keyword_coverage(query, doc_texts)\n",
    "\n",
    "# Pair each document with its coverage score and sort by score descending\n",
    "ranked_coverage = sorted(zip(retrieved_docs, coverage_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display ranked results\n",
    "print(\" KEYWORD COVERAGE EVALUATION:\")\n",
    "for i, (doc, score) in enumerate(ranked_coverage, 1):\n",
    "    print(f\"[{i}] Coverage Score: {score:.4f}\")\n",
    "    print(f\"    Source: {doc['metadata'].get('file_name', 'N/A')}\")\n",
    "    print(f\"    Excerpt: {doc['text'][:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19e8c7",
   "metadata": {},
   "source": [
    "3. Content Density Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e71387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CONTENT DENSITY EVALUATION:\n",
      "[1] Density Score: 1.0000\n",
      "    Source: 8.txt\n",
      "    Excerpt: . These legendary heroes of ancient Greece not only entertained with their tales but also served as important cultural symbols. They embodied qualitie...\n",
      "\n",
      "[2] Density Score: 1.0000\n",
      "    Source: 9.txt\n",
      "    Excerpt: The tales of these heroes also served as a means of explaining natural phenomena and human experiences. For example, Heracles's Twelve Labors could be...\n",
      "\n",
      "[3] Density Score: 1.0000\n",
      "    Source: 7.txt\n",
      "    Excerpt: The Legendary Heroes of Ancient Greece Ancient Greece is known for its rich mythology and fascinating stories of heroes. These legendary figures have ...\n",
      "\n",
      "[4] Density Score: 1.0000\n",
      "    Source: 9.txt\n",
      "    Excerpt: . In conclusion, the legendary heroes of ancient Greece, such as Heracles, Theseus, and Perseus, have left an indelible mark on Greek culture and cont...\n",
      "\n",
      "[5] Density Score: 1.0000\n",
      "    Source: 8.txt\n",
      "    Excerpt: . The stories of these heroes were often used as cautionary tales or as examples of virtue to inspire and guide individuals...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def score_content_density(query, docs):\n",
    "    \"\"\"\n",
    "    Measures information density - how much relevant content per document length\n",
    "    Combines keyword frequency with document length normalization\n",
    "    \"\"\"\n",
    "    # Extract query keywords (remove stop words)\n",
    "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'what', 'how', 'why', 'when', 'where'}\n",
    "    query_words = [word.lower() for word in re.findall(r'\\b\\w+\\b', query) if word.lower() not in stop_words]\n",
    "    \n",
    "    if not query_words:\n",
    "        return [0.0] * len(docs)\n",
    "    \n",
    "    scores = []\n",
    "    for doc in docs:\n",
    "        doc_lower = doc.lower()\n",
    "        doc_words = doc.split()\n",
    "        \n",
    "        # Count query word occurrences in document\n",
    "        keyword_count = 0\n",
    "        for query_word in query_words:\n",
    "            keyword_count += doc_lower.count(query_word)\n",
    "        \n",
    "        # Calculate density: keyword_frequency / document_length  \n",
    "        # Add small constant to avoid division by zero\n",
    "        density_score = keyword_count / (len(doc_words) + 1)\n",
    "        \n",
    "        # Normalize to 0-1 range (multiply by 100 for better scale)\n",
    "        normalized_score = min(density_score * 100, 1.0)\n",
    "        scores.append(normalized_score)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "# Get content density scores\n",
    "doc_texts = [doc['text'] for doc in retrieved_docs]\n",
    "density_scores = score_content_density(query, doc_texts)\n",
    "\n",
    "# Pair each document with its density score and sort by score descending\n",
    "ranked_density = sorted(zip(retrieved_docs, density_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display ranked results\n",
    "print(\" CONTENT DENSITY EVALUATION:\")\n",
    "for i, (doc, score) in enumerate(ranked_density, 1):\n",
    "    print(f\"[{i}] Density Score: {score:.4f}\")\n",
    "    print(f\"    Source: {doc['metadata'].get('file_name', 'N/A')}\")\n",
    "    print(f\"    Excerpt: {doc['text'][:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ebee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
