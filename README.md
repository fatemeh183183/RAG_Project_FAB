ğŸ“š Local Q&A Chatbot with Citations (RAG System)
An end-to-end Retrieval-Augmented Generation (RAG) application that enables users to ask questions over a local document corpus and receive citation-grounded answers using hybrid retrieval, reranking, and large language models.
This project demonstrates production-style RAG design, including chunking optimization, hybrid search, reranking, hallucination control, evaluation metrics, and a Streamlit UI.

ğŸš€ Key Features


ğŸ” Hybrid Retrieval


Dense vector search (OpenAI embeddings)


Lexical search (BM25)




ğŸ§  Multi-stage Reranking


Semantic filtering (bi-encoder)


Precision reranking (cross-encoder)




ğŸ“ Citation-Grounded Answers


Inline source attribution ([[SOURCE: file.txt]])


Transparent evidence display




ğŸ§ª Evaluation & Hallucination Detection


RAGAS (faithfulness, answer relevancy)


Semantic hallucination checks


ROUGE & BLEU metrics




ğŸ’¾ Offline Embedding Storage


Embeddings saved locally (.pkl)


No re-embedding required at runtime




ğŸ–¥ï¸ Interactive Streamlit UI


Upload embeddings


Ask questions


View answers, sources, and supporting documents





ğŸ—ï¸ Architecture Overview
Documents (.txt)
      â†“
Text Cleaning & Chunking (Optimal Chunk Size)
      â†“
OpenAI Embeddings
      â†“
Local Storage (.pkl)
      â†“
Hybrid Retrieval
   â”œâ”€â”€ Dense Vector Search
   â”œâ”€â”€ BM25 Lexical Search
      â†“
Candidate Merge & Deduplication
      â†“
Semantic Filtering (Bi-Encoder)
      â†“
Cross-Encoder Reranking
      â†“
LLM Answer Generation (with citations)
      â†“
Evaluation & UI Display


ğŸ§© Tech Stack


Language: Python 3.11


LLM: OpenAI GPT-3.5


Embeddings: OpenAI text-embedding-3-small


Retrieval:


SentenceTransformers


BM25 (rank-bm25)




Reranking: Cross-Encoder (ms-marco-MiniLM-L-6-v2)


Evaluation:


RAGAS


ROUGE / BLEU




UI: Streamlit


Storage: Pickle (.pkl)



ğŸ“‚ Project Structure
New_FAB_Project/
â”‚
â”œâ”€â”€ main_app.py              # Streamlit RAG application
â”œâ”€â”€ Chatbot_GPT.ipynb        # RAG pipeline & evaluation notebook
â”œâ”€â”€ Chatbot_Open.ipynb       # Experiments & analysis
â”œâ”€â”€ embedded_chunks_safe.pkl # Saved embeddings
â”œâ”€â”€ ancient_greece_data/     # Source documents
â”œâ”€â”€ .env                     # Environment variables
â””â”€â”€ README.md


âš™ï¸ Setup Instructions
1ï¸âƒ£ Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

2ï¸âƒ£ Install dependencies
pip install -U pip
pip install streamlit openai sentence-transformers rank-bm25 scikit-learn numpy

3ï¸âƒ£ Add OpenAI API key
Create a .env file:
OPENAI_API_KEY=your_api_key_here


â–¶ï¸ Run the Application
streamlit run main_app.py

Then open:
http://localhost:8501


ğŸ–±ï¸ How to Use


Enter your OpenAI API key


Upload the saved embeddings file (.pkl)


Ask a question


View:


Answer with inline citations


Source list


Top supporting documents





ğŸ“Š Evaluation & Quality Control
This project includes multiple layers of evaluation:


RAGAS Metrics


Faithfulness


Answer Relevancy




Hallucination Detection


Sentence-level semantic similarity checks




Lexical & Semantic Metrics


ROUGE-1 / ROUGE-2 / ROUGE-L


BLEU score


# Local Q&A Chatbot with Citations

This is a Streamlit-based RAG application for local document Q&A with citations.

## Live Demo
ğŸ‘‰ [(https://ragprojectfab-jjcas8myfqnrgjgq25nymr.streamlit.app/)

## How to use
1. Open the app using the link above
2. Enter your own OpenAI API key
3. Upload the embedded `.pkl` file
4. Ask questions












